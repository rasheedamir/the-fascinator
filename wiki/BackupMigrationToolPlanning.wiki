#summary A planning document for a Backup/Migration tool
= Introduction =
I'm starting to look at building a tool similar to the !HarvestClient (in that it can be run outside of the server) that would grab a backed up storage directory/plugin and rebuild a system on top of it. There are some old skeletons in Fascinator's closet that will cause problems here depending on the scope however, so I thought I'd put together some thoughts on how to proceed.

= Background =
This is issue has [https://fascinator.usq.edu.au/trac/wiki/tf2/DeveloperNotes/investigations/BackupRestore come up before], and it was very messy then as well. Mostly it was messy because there are several feature requests converging here that muddy the waters, such as replication, synchronization and migration between multiple instances of The Fascinator that are running at the same time.

The reality however at this stage, is that all deployed instances of the Fascinator (that I am aware of) do not make use of this sort of functionality... it was all design work to build towards future ideas.

=== Problem 1: No Solr Index ===
Existing in-system scripts that re-index or re-harvest the entire system are critically flawed. They rely on the existence of the Solr index to return a list of OIDs that are stored in the system.

This can causes problem not during a backup, but sometimes when and index event fails because you are working on the python script invovled you are suddenly left with an orphan record in storage that is invisible to the user interface.

The Solr index has always been the preferred option simply because it allows the process to proceed in an efficient fashion, paging through page after page of search results. The only alternative is avoided inside the system because the Storage API exposes a general '`getObjectIdList()`', but is primitive and tries to return a list of every ID in storage inside a single Object. This solution will not scale to large datasets without causing significant memory problems.

However, '`getObjectIdList()`' is the only choice at this stage for a storage based restore, simply because the Solr index does not exist.

=== Problem 2: Object ID Generation ===
The Storage API allows you to use any object ID you desire, but most harvester make use of a common utility library provided by the system core which takes several strings and hashes them together:
 * The complete path to the ingested file.
 * The server's host name.
 * The System's username running the server.

As mentioned earlier, there is history there, relating to desktop deployments of The Fascinator talking to each other and/or a server, so those Strings were picked as an initial attempt to ensure unique OIDs were all but guaranteed.

Server's such as Mint/ReDBox have partially addressed this issue by providing different OID generation algorithms. For example, the CSV Harvester (used by Mint to ingest most data) instead hashes:
 * The file name holding the CSV data (but not the file path).
 * A configured String (`recordIDPrefix`).
 * The ID column (or row number if absent).

This method allows each data source (combination of file and '`recordIDPrefix`') that bothers to provide it's own identifier (or some unique data column) to generate the same OID every time, no matter which server ingests the data. This is important if you are going to (for example) reload your institutional Party data periodically with updates, since you don't want to be creating new duplicate entries for each person.

Where this issue hasn't been addressed however is in the creation of internally used OIDs, such as harvest files and packages. So if you were to move server, path or username all of your harvest files will suddenly change OID. Leading to...

=== Problem 3: Linking to Harvest Files ===
Each object has the OID of both the configuration and rules files from its original data source embedded in its metadata. More detail on this setup makes sense if you are familiar with the [https://sites.google.com/site/fascinatorhome/home/documentation/technical/details/object-life-cycle general make up of an object].

The problem arises however if/when the OID for the harvest file changes